---
title: "Distribuciones de Probabilidad"
editor: visual
author: "Fabián Brenes Trejos"
toc: true
number-sections: true
code-fold: true
html-math-method: katex
theme:
  - cosmo
  - ../../Plantillas/fmbt_doc.scss
bibliography: ../../referencias.bib
cite: |
  @Sahu2024
  @Hogg2015
---

# Distribuciones de Probabilidad de una Variable Aleatoria

En un experimento aleatorio con resultados en el espacio $S$, una función $X$ que asigna un único número real $X(s) = x$ a cada elemento $s$ en $S$ se define como **variable aleatoria**. El espacio de $X$ es el conjunto de números reales $\{x:X(s) = x, s \in S\}$.

Es decir, una **variable aleatoria** puede asumir valores de un experimento aleatorio específico. Por ejemplo: los posibles resultados de tirar una moneda al aire y obtener cara o escudo, en este caso, se puede denotar la variable aleatoria $X$ para la cantidad de caras obtenidas al tirar la moneda cierta cantidad de veces.

Por otra parte, una distribución de probabilidad distribuye el total de la probabilidad (que equivale a 1 o 100%) entre todos los posibles valores de la variable aleatoria.

## Esperanza Matemática

Ese el valor promedio de una variable aleatoria. Se calcula como la suma o la integral de los valores $x$ multiplicado por la probabilidad.

$$
  E(X) = \mu =
    \begin{cases}
      \sum_{all x}{x f(x)} \quad  \text{si $X$ es discreta,} \\
      \int ^ {\infty} _ {-\infty} {x f(x) dx} \quad  \text{si $X$ es aleatoria}
    \end{cases}    
$$

**Ejemplo:** Esperanza matemática de lanzar un dado con 6 caras y una probabilidad de $1 / 6$ de obtener cada lado.

```{r}

X <- seq(1:6)

prob <- 1 / length(X)

mu = sum(X * prob)

cat("E(X):", mu)

```

**Ejemplo:** Considere una distribución uniforme $U(a,b)$ con pdf $f(x) = \frac{1}{b - a}, a\le x \le b$.

$$
\begin{align}
E(X) = & \int ^ {\infty} _ {-\infty} x f(x) dx \notag \\
& \int ^ {b} _ {a} x * \frac{1}{b-a} dx \notag \\
& \frac{1}{b-a} \int ^ {b} _ {a} x  dx \notag \quad \notag \\
& F(x) = \frac{x ^ 2}{2} \notag \quad \notag \\
& \Big| ^ b _ a = \frac{1}{b-a} * \frac{b ^ 2}{2} - \frac{1}{b - a} * \frac{a ^ 2}{2} \notag \\ 
& \Big| ^ b _ a = \frac{b ^ 2}{2(b - a)} - \frac{a ^ 2}{2(b - a)} \notag \\
& \Big| ^ b _ a = \frac{b ^ 2 - a ^ 2}{2(b - a)} \notag \\
& \Big| ^ b _ a = \frac{(b - a)(b + a)}{2(b - a)} \notag \\
E(X) = & \frac{(b + a)}{2} \notag \\
\end{align}
$$

## Varianza

Mide la variabilidad de una variable aleatoria.

$$
  Var(X)  = E(X - \mu) ^ 2 = \sigma ^ 2 = 
    \begin{cases}
      \sum_{all x}{(x - \mu) ^ 2} f(x) \quad  \text{si $X$ es discreta,} \\
      \int ^ {\infty} _ {-\infty} {(x - \mu) ^ 2 f(x) dx} \quad  \text{si $X$ es aleatoria}
    \end{cases}    
$$

La varianza de una variable aleatoria es el valor esperado de su cuadrado menos el cuadrado de su valor esperado.

$$
\begin{align}
Var(X) = & E(X - \mu) ^ 2 \notag \\
& E(X ^ 2 - 2 X \mu + \mu ^ 2) \quad \text{Aplicando fórmula notable} \notag \\
& E(X ^ 2) - 2 E(X) \mu + \mu ^ 2 \notag \\
& E(X ^ 2) - 2 \mu \mu + \mu ^ 2 \quad \text{Dado que $E(X) = \mu$} \notag \\
& E(X ^ 2) - 2\mu ^ 2 + \mu ^ 2 \notag \\
& E(X ^ 2) - \mu ^ 2 \notag
\end{align}
$$

## Cuantiles
Son medidas que separan la distribución en diferentes partes iguales. Por ejemplo la mediana (llamada el percentil 50), separa la distribución en dos partes iguales. Utilizando la distribución de probabilidad acumulada, la mediana se obtiene al resolver la ecuación $F(x) = 0.5$. 
En general se define el $p ^ {to}$ quintil  se obtiene a solucionar la siguiente ecuación:

$$
F(x) = p, \quad \text{Para cada } 0 < p < 1.
$$
**Ejemplo:** Para la distribución uniforme definida por el *pdf*:

$$
f(x) = \frac{1}{b - a}, \text{ si }  a < \le x \le b
$$
Donde, según el teorema fundamental del cálculo:

$$
f(x) =  \frac{dF(x)}{dx}
$$
Se obtiene: 

$$
\begin{align}
F(x) = & \int ^ {x} _ {a} \frac{1}{b - a} dx  \notag \\
F(x) = & 1 \frac{1}{b-a}\int ^ {x} _ {a} \frac{1}{b - a} dx \notag \\
\end{align}
$$
## Distribuciones Discretas

Para variables discretas se define la función $f(x)$ para denotar $P(X = x)$, en donde $f(x)$ es la función de probabilidad o la **función de masa de probabilidad** (pmf por sus siglas en inglés) de la variable aleatoria $X$.

La pmf $f(x)$ de una variable discreta $X$ cumple las siguientes condiciones:

$$
\begin{align}
&\textrm{(a)} \quad f(x) > 0, \quad x \in S; \notag \\
&\textrm{(b)} \quad \sum_{x \in S} f(x) = 1; \notag \\
&\textrm{(c)} \quad P(X \in A) = \sum_{x \in A} f(x), \quad \textrm{donde} \quad A \subset S. \notag \\   
\end{align}
$$

**Funciones de probabilidad acumulada** (cdf por sus siglas en inglés) corresponde a $F(x) = P(X \leq x)$, donde $-\infty < x < \infty$.

### Distribución de Bernoulli

### Distribución Binomial

### Distribución Geométrica

## Distribuciones Continuas

Para una variable continua, $P(X = x)$...

#### Esperanza Matemática de una variable Continua

# Referencias
